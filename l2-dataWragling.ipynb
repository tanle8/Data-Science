{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### CSV exercises\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File  does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-022d8660e486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpath_to_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mpath_to_new_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0madd_full_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_new_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-022d8660e486>\u001b[0m in \u001b[0;36madd_full_name\u001b[0;34m(path_to_csv, path_to_new_csv)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#WRITE YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Create a dataframe which hosted the data from csv file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mbaseball_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Create new header called nameFull which contain full name of player.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mbaseball_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nameFull'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseball_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nameFirst'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbaseball_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nameLast'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/temp/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/temp/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/temp/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/temp/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/temp/anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File  does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_full_name(path_to_csv, path_to_new_csv):\n",
    "    #Assume you will be reading in a csv file with the same columns that the\n",
    "    #Lahman baseball data set has -- most importantly, there are columns\n",
    "    #called 'nameFirst' and 'nameLast'.\n",
    "    #1) Write a function that reads a csv\n",
    "    #located at \"path_to_csv\" into a pandas dataframe and adds a new column\n",
    "    #called 'nameFull' with a player's full name.\n",
    "    #\n",
    "    #For example:\n",
    "    #   for Hank Aaron, nameFull would be 'Hank Aaron', \n",
    "\t#\n",
    "\t#2) Write the data in the pandas dataFrame to a new csv file located at\n",
    "\t#path_to_new_csv\n",
    "\n",
    "\n",
    "    #WRITE YOUR CODE HERE\n",
    "    # Create a dataframe which hosted the data from csv file.\n",
    "    baseball_data = pd.read_csv(path_to_csv)\n",
    "    # Create new header called nameFull which contain full name of player.\n",
    "    baseball_data['nameFull'] = baseball_data['nameFirst'] + ' ' + baseball_data['nameLast']\n",
    "    # Write the new thing to new csv file \n",
    "    baseball_data.to_csv(path_to_new_csv)\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For local use only\n",
    "    # If you are running this on your own machine add the path to the\n",
    "    # Lahman baseball csv and a path for the new csv.\n",
    "    # The dataset can be downloaded from this website: http://www.seanlahman.com/baseball-archive/statistics\n",
    "    # We are using the file Master.csv\n",
    "    path_to_csv = \"\"\n",
    "    path_to_new_csv = \"\"\n",
    "    add_full_name(path_to_csv, path_to_new_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pandasql",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c6b14d216763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandasql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mselect_first_50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pandasql"
     ]
    }
   ],
   "source": [
    "# Relational Database\n",
    "\n",
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def select_first_50(filename):\n",
    "    # Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\n",
    "    # by replacing spaces with underscores and setting all characters to lowercase, so the\n",
    "    # column names more closely resemble columns names one might find in a table.\n",
    "    aadhaar_data = pandas.read_csv(filename)\n",
    "    aadhaar_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "\n",
    "    # Select out the first 50 values for \"registrar\" and \"enrolment_agency\"\n",
    "    # in the aadhaar_data table using SQL syntax. \n",
    "    #\n",
    "    # Note that \"enrolment_agency\" is spelled with one l. Also, the order\n",
    "    # of the select does matter. Make sure you select registrar then enrolment agency\n",
    "    # in your query.\n",
    "    #\n",
    "    # You can download a copy of the aadhaar data that we are passing \n",
    "    # into this exercise below:\n",
    "    # https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/aadhaar_data.csv\n",
    "    # SELECT Headers (Attributes) FROM DataFrame with Limitation number of items which will be selected.\n",
    "    q = \"\"\"\n",
    "    -- YOUR QUERY HERE\n",
    "    \n",
    "    SELECT registrar, enrolment_agency FROM aadhaar_data LIMIT 50;\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #Execute your SQL command against the pandas frame\n",
    "    aadhaar_solution = pandasql.sqldf(q.lower(), locals())\n",
    "    return aadhaar_solution    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "More about PandasSQL package:\n",
    "\n",
    "The [pandasql](https://pypi.python.org/pypi/pandasql) package allows us to perform queries on dataframes using the [SQLite syntax](http://www.sqlite.org/lang.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### More complex SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pandasql",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b1e63014c6c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandasql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maggregate_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pandasql"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import pandasql\n",
    "\n",
    "def aggregate_query(filename):\n",
    "    # Read in our aadhaar_data csv to a pandas dataframe.  Afterwards, we rename the columns\n",
    "    # by replacing spaces with underscores and setting all characters to lowercase, so the\n",
    "    # column names more closely resemble columns names one might find in a table.\n",
    "    \n",
    "    aadhaar_data = pandas.read_csv(filename)\n",
    "    aadhaar_data.rename(columns = lambda x: x.replace(' ', '_').lower(), inplace=True)\n",
    "\n",
    "    # Write a query that will select from the aadhaar_data table how many men and how \n",
    "    # many women over the age of 50 have had aadhaar generated for them in each district.\n",
    "    # aadhaar_generated is a column in the Aadhaar Data that denotes the number who have had\n",
    "    # aadhaar generated in each row of the table.\n",
    "    #\n",
    "    # Note that in this quiz, the SQL query keywords are case sensitive. \n",
    "    # For example, if you want to do a sum make sure you type 'sum' rather than 'SUM'.\n",
    "    #\n",
    "\n",
    "    # The possible columns to select from aadhaar data are:\n",
    "    #     1) registrar\n",
    "    #     2) enrolment_agency\n",
    "    #     3) state\n",
    "    #     4) district\n",
    "    #     5) sub_district\n",
    "    #     6) pin_code\n",
    "    #     7) gender\n",
    "    #     8) age\n",
    "    #     9) aadhaar_generated\n",
    "    #     10) enrolment_rejected\n",
    "    #     11) residents_providing_email,\n",
    "    #     12) residents_providing_mobile_number\n",
    "    #\n",
    "    # You can download a copy of the aadhaar data that we are passing \n",
    "    # into this exercise below:\n",
    "    # https://s3.amazonaws.com/content.udacity-data.com/courses/ud359/aadhaar_data.csv\n",
    "        \n",
    "    q = \"\"\"SELECT gender, district, SUM(aadhaar_generated) FROM aadhaar_data WHERE age>50 GROUP BY gender, district;\"\"\"\n",
    "    \n",
    "\n",
    "    # Execute your SQL command against the pandas frame\n",
    "    aadhaar_solution = pandasql.sqldf(q.lower(), locals())\n",
    "    return aadhaar_solution    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### API excercise\n",
    "\n",
    "We can access data on files or database but what about the data that sits in websites.\n",
    "We need to crawl the websites and parsing through all html is complicated. Another way is using this website's api (application programming interface) which can provide us machine readable format data.\n",
    "There are several different kinds of APIs but one of the most common types is `representational state transfer` (REST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pprint\n",
    "\n",
    "def api_get_request(url):\n",
    "    # In this exercise, you want to call the last.fm API to get a list of the\n",
    "    # top artists in Spain. The grader will supply the URL as an argument to\n",
    "    # the function; you do not need to construct the address or call this\n",
    "    # function in your grader submission.\n",
    "    # \n",
    "    # Once you've done this, return the name of the number 1 top artist in\n",
    "    # Spain. \n",
    "    # More about pprint here: https://docs.python.org/2/library/pprint.html\n",
    "    \n",
    "    # Make API call using the request library and load the results into a dictionary.\n",
    "    data = requests.get(url).text\n",
    "    data = json.loads(data)\n",
    "    \n",
    "    pp = pprint.PrettyPrinter(indent = 4)\n",
    "    # Print out the name of the #1 artist, we look at the topartists \n",
    "    # key then artist key then the first entry and there is the name.\n",
    "    pp.pprint(data['topartists']['artist'][0]['name'])\n",
    "    \n",
    "    return data['topartists']['artist'][0]['name']     # return the top artist in Spain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation excercise\n",
    "\n",
    "Dealing with missing data.\n",
    "One explanation for missing data is \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "def imputation(filename):\n",
    "    # Pandas dataframes have a method called 'fillna(value)', such that you can\n",
    "    # pass in a `single value` to replace any NAs in a dataframe or series. You\n",
    "    # can call it like this: \n",
    "    #     dataframe['column'] = dataframe['column'].fillna(value)\n",
    "    #\n",
    "    # Using the numpy.mean function, which calculates the mean of a numpy\n",
    "    # array, impute any missing values in our Lahman baseball\n",
    "    # data sets 'weight' column by setting them equal to the average weight.\n",
    "    # \n",
    "    # You can access the 'weight' colum in the baseball data frame by\n",
    "    # calling baseball['weight']\n",
    "\n",
    "    baseball = pandas.read_csv(filename)\n",
    "    \n",
    "    #YOUR CODE GOES HERE\n",
    "    mean_weight = numpy.mean(baseball['weight'])\n",
    "    # print mean_weight\n",
    "    baseball['weight'] = baseball['weight'].fillna(mean_weight)\n",
    "    \n",
    "    \n",
    "\n",
    "    return baseball"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
