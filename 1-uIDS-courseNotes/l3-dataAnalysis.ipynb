{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lesson 3: Data Analysis\n",
    "\n",
    "## Statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Terminology\n",
    "- `Significant level`\n",
    "    In statistical hypothesis testing, a result has statistical significance when it is very unlikely to have occurred given the null hypothesis.[3] More precisely, the significance level defined for a study, α, is the probability of the study rejecting the null hypothesis, given that it were true; and the p-value of a result, p, is the probability of obtaining a result at least as extreme, given that the null hypothesis were true. The result is statistically significant, by the standards of the study, when p < α.\n",
    "    [Link to wikipedia article](https://en.wikipedia.org/wiki/Statistical_significance)\n",
    "- `Normal Distribution`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/umJQ6gVT8kY\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kurt's Introduction\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/umJQ6gVT8kY\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DyeRm96wH5M\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why is Statistics Useful?\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/DyeRm96wH5M\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ZfOTcwXAdEw\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Introduction to Normal (Gauss Distribution)\n",
    "from IPython.display import HTML\n",
    "HTML ('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ZfOTcwXAdEw\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The equation for the normal distribution is:\n",
    "\n",
    "$$f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}.e^{\\frac{-(x - \\mu)^2}{2\\sigma^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### T-Test\n",
    "To be more explicit:\n",
    "- It is important to note that you cannot \"accept\" a null.\n",
    "- You can just \"retain\" or \"fail to reject\".\n",
    "\n",
    "If you would like to learn more about the t-test, check out [this lesson](https://classroom.udacity.com/courses/ud201/lessons/1333678604/concepts/1470193200923) in Intro to Inferential Statistics.\n",
    "\n",
    "Welch's T-Test In Python\n",
    "You can check out additional information about the scipy implementation of the t-test below:\n",
    "http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"369\" height=\"208\" src=\"https://www.youtube.com/embed/tjSj2OkV51A\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t-Test video\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"369\" height=\"208\" src=\"https://www.youtube.com/embed/tjSj2OkV51A\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"369\" height=\"208\" src=\"https://www.youtube.com/embed/B_1cnwYn7so\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Welch's Two-Sample t-Test\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"369\" height=\"208\" src=\"https://www.youtube.com/embed/B_1cnwYn7so\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 14. Quiz - Welch's t-Test Exercise\n",
    "\n",
    "Performs a **t-test** on two sets of baseball data (left-handed and right-handed hitters).\n",
    "\n",
    "You will be given a csv file that has *three* columns.\n",
    "A player's `name`, `handedness` (L for lefthanded or R for righthanded) and their\n",
    "`career batting average` (called 'avg').\n",
    "You can look at the csv file by downloading the baseball_stats file from Downloadables below. \n",
    "\n",
    "Write a function that will:\n",
    "- read that the csv file into a pandas data frame,and\n",
    "- Run Welch's t-test on the two cohorts defined by handedness.\n",
    "  - One cohort should be a data frame of right-handed batters. And \n",
    "  - the other cohort should be a data frame of left-handed batters.\n",
    "\n",
    "We have included the `scipy.stats` library to help you write\n",
    "or implement **Welch's t-test**:\n",
    "http://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "\n",
    "With a significance level of 95%, if there is no difference\n",
    "between the two cohorts, return a tuple consisting of\n",
    "True, and then the tuple returned by scipy.stats.ttest.  \n",
    "\n",
    "If there is a difference, return a tuple consisting of\n",
    "False, and then the tuple returned by scipy.stats.ttest.\n",
    "\n",
    "For example, the tuple that you return may look like:\n",
    "(True, (9.93570222, 0.000023))\n",
    "\n",
    "Supporting materials\n",
    "[baseball_stats.csv](https://www.udacity.com/api/nodes/702578673/supplemental_media/baseball-statscsv/download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.stats\n",
    "import pandas\n",
    "\n",
    "def compare_averages(filename):\n",
    "    \"\"\"\n",
    "    The description for this quiz is above text.\n",
    "    \"\"\"\n",
    "    baseball_data = pandas.read_csv(filename)\n",
    "    lh_player = baseball_data.loc[baseball_data['handedness'] == 'L', 'avg']\n",
    "    rh_player = baseball_data.loc[baseball_data['handedness'] == 'R', 'avg']\n",
    "    \n",
    "    # Welch's t-test\n",
    "    (t, p) = scipy.stats.ttest_ind(lh_player, rh_player, equal_var=False)\n",
    "    \n",
    "    # Welch's t-test results.\n",
    "    result = (p > 0.05, (t, p))\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Your calculated t-statistic is 9.93570222624\n",
    "The correct t-statistic is +/-9.93570222624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"550\" height=\"309\" src=\"https://www.youtube.com/embed/TrSU-GH7TDY\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exaplaination for Welch's t-Test exercise\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"550\" height=\"309\" src=\"https://www.youtube.com/embed/TrSU-GH7TDY\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Non-normal Data\n",
    "\n",
    "When performing the t-Test, we assume that our data is normal.\n",
    "In the wild, you'll often encounter probability distributions.\n",
    "They're distinctly not normal. They might look like two diagrams below or even completely different.\n",
    "\n",
    "![non-normal data example](image/l3-1-1.png)\n",
    "\n",
    "As you imagine, there are still statistical tests that we can utilize when our data is not normal.\n",
    "\n",
    "First of, we should have some machinery in place for determining whether or not our data is **Gaussian** in the first place. A crude, inaccurate way of determining whether or not our data is normal is simply to plot a histogram of our data ans ask, does this look like a bell curve? In both of the cases above, the answer would definitely be no. But, we can do  little bit better than that. There are some statistical tests that we can use to measure the likelihood that a sample is drawn from a normally distributed population. One such test is the **Shapiro-Wilk** test. The theory of this test is out of this course's scope. But you can implement this test easyly like this:\n",
    "\n",
    "```Python\n",
    "(W, p) = scipy.stats.shapiro(data)\n",
    "```\n",
    "- with `W` is the Shapiro-Wilk test statistic, \n",
    "- `p` value, which should be interpreted the same way as we would interpret the p-value for our t-test.\n",
    "\n",
    "That is, given null hypothesis that this data is drawn from a normal distribution, what is the likelihood that we would observe a value of W that was at least as extreme as the one that we see?\n",
    "\n",
    "\n",
    "### Non-Parametric Test\n",
    "\n",
    "A statistical test that does not assume our data is drawn from any particular underlying probability distribution.\n",
    "\n",
    "Mann-Whitney U test is a test that tests null hypothesis that two populations are the same:\n",
    "\n",
    "```Python\n",
    "(U, P) = scipy.stats.mannwhitneyu(x, y)\n",
    "```\n",
    "- x and y are two samples.\n",
    "\n",
    "### Note\n",
    "These have just been some of the methods that we can use when performing statistical tests on data. As you can imagine, there are a number of additional ways to handle data from different probability distributions or data that looks like it came from no probability distribution whatsoever.\n",
    "\n",
    "Data scientist can perform many statistical procedures. But it's vital to understand the underlying structure of the data set and consequently, which statistical tests are appropriate given the data that we have.   \n",
    "\n",
    "There are many different types of statistical tests and even many different schools of thought within statistics regarding the correct way to analyze data. This has really just been an opportunity to get your feet wet with statistical analysis. *It's just the tip of the iceberg*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. What is Machine Learning?\n",
    "In addition to statistics, many data scientists are well versed in machine learning.\n",
    "Machine Learning is a branch of artificial intelligence that's focused on constructing systems that learn from large amounts of data to make predictions.\n",
    "\n",
    "\n",
    "These are all the potential applications of machine learning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"846\" height=\"476\" src=\"https://www.youtube.com/embed/uKEm9_HvkKQ\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why is Machine Learning Useful?\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"846\" height=\"476\" src=\"https://www.youtube.com/embed/uKEm9_HvkKQ\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Statistics vs. Machine Learning\n",
    "What is the difference between statistics and machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"798\" height=\"449\" src=\"https://www.youtube.com/embed/qwUYjU_kmdc\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kurt's Favorite ML Algorithm\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"798\" height=\"449\" src=\"https://www.youtube.com/embed/qwUYjU_kmdc\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Different Types of Learning\n",
    "\n",
    "### Prediction with Regression\n",
    "\n",
    "### Linear Regression with Gradient\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "#### How to minimize the cost function\n",
    "\n",
    "### Gradient Descent in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Gradient Descent in Python\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "def compute_cost(features, values, theta):\n",
    "    \"\"\"\n",
    "    Compute the cost of a list of parameters - theta, given a list of features \n",
    "    (input data points) and values (output data points).\n",
    "    \"\"\"\n",
    "    m = len(values)\n",
    "    sum_of_square_errors = numpy.square(numpy.dot(features, theta) - values).sum()\n",
    "    cost = sum_of_square_errors / (2*m)\n",
    "\n",
    "    return cost\n",
    "\n",
    "def gradient_descent(features, values, theta, alpha, num_iterations):\n",
    "    \"\"\"\n",
    "    Perform gradient descent given a data set with an arbitrary number of features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Write code here that performs num_iterations updates to the elements of theta.\n",
    "    # times. Every time you compute the cost for a given list of thetas, append it \n",
    "    # to cost_history.\n",
    "    # See the Instructor notes for hints. \n",
    "    \n",
    "    cost_history = []\n",
    "    m = len(values) \n",
    "    ###########################\n",
    "    ### YOUR CODE GOES HERE ###\n",
    "    ###########################\n",
    "    for iteration in range(num_iterations):\n",
    "        # Append new cost of given list of theta to cost_history\n",
    "        cost_history.append(compute_cost(features, values, theta))\n",
    "        # compute gradient descent\n",
    "        diff = numpy.dot(features.transpose(), values - numpy.dot(features, theta))\n",
    "        theta = theta + (alpha/m)*diff\n",
    "    \n",
    "    return theta, pandas.Series(cost_history) # leave this line for the grader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Theta =\n",
    "[ 45.35759233  -9.02442042  13.69229668]\n",
    "\n",
    "Cost History = \n",
    "0      3769.194036\n",
    "1      3748.133469\n",
    "2      3727.492258\n",
    "3      3707.261946\n",
    "4      3687.434249\n",
    "5      3668.001052\n",
    "6      3648.954405\n",
    "7      3630.286519\n",
    "8      3611.989767\n",
    "9      3594.056675\n",
    "10     3576.479921\n",
    "11     3559.252334\n",
    "12     3542.366888\n",
    "13     3525.816700\n",
    "14     3509.595027\n",
    "15     3493.695263\n",
    "16     3478.110938\n",
    "17     3462.835711\n",
    "18     3447.863371\n",
    "19     3433.187834\n",
    "20     3418.803138\n",
    "21     3404.703444\n",
    "22     3390.883030\n",
    "23     3377.336290\n",
    "24     3364.057733\n",
    "25     3351.041978\n",
    "26     3338.283754\n",
    "27     3325.777897\n",
    "28     3313.519347\n",
    "29     3301.503147\n",
    "          ...     \n",
    "970    2686.739779\n",
    "971    2686.739192\n",
    "972    2686.738609\n",
    "973    2686.738029\n",
    "974    2686.737453\n",
    "975    2686.736881\n",
    "976    2686.736312\n",
    "977    2686.735747\n",
    "978    2686.735186\n",
    "979    2686.734628\n",
    "980    2686.734074\n",
    "981    2686.733523\n",
    "982    2686.732975\n",
    "983    2686.732431\n",
    "984    2686.731891\n",
    "985    2686.731354\n",
    "986    2686.730820\n",
    "987    2686.730290\n",
    "988    2686.729764\n",
    "989    2686.729240\n",
    "990    2686.728720\n",
    "991    2686.728203\n",
    "992    2686.727690\n",
    "993    2686.727179\n",
    "994    2686.726672\n",
    "995    2686.726168\n",
    "996    2686.725668\n",
    "997    2686.725170\n",
    "998    2686.724676\n",
    "999    2686.724185\n",
    "dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Coefficients Of Determination\n",
    "We need some ways to evaluate the effectiveness of our models. \n",
    "One way we can measure this is a quantity called the coefficient of determination also referred to as $R^2$.\n",
    "We can define the coefficients of determination ($R^2$).\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_n(y_i - f_i)^2}{\\sum_n(y_i - \\bar{y})^2}$$\n",
    "\n",
    "- Note:\n",
    "  - data: $y_i ... y_n$\n",
    "  - predictions: $f_i ... f_n$\n",
    "  - average of data: $\\bar{y}$\n",
    "\n",
    "- The closer $R^2$ to `1`, the better our models.\n",
    "- The closer $R^2$ to `0`, the poorer our models.\n",
    "\n",
    "### Quiz: Calculating R^2\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "def compute_r_squared(data, predictions):\n",
    "    # Write a function that, given two input numpy arrays, 'data', and 'predictions,'\n",
    "    # returns the coefficient of determination, R^2, for the model that produced \n",
    "    # predictions.\n",
    "    # \n",
    "    # Numpy has a couple of functions -- np.mean() and np.sum() --\n",
    "    # that you might find useful, but you don't have to use them.\n",
    "\n",
    "    # YOUR CODE GOES HERE\n",
    "    r_squared = 1 - sum((predictions - data)**2) / sum((data - np.mean(data))**2)\n",
    "    \n",
    "    return r_squared\n",
    "```\n",
    "\n",
    "### Other Considerations\n",
    "- Other types of linear regression\n",
    "  - Ordinary lest squares regression\n",
    "- Parameter estimation\n",
    "- Under/Overfitting\n",
    "- Multiple local minima\n",
    "\n",
    "\n",
    "### Kurt's Advice For ML Best Practices\n",
    "\n",
    "Qualitative viewpoint:\n",
    "Any problem you're looking at, it's always very valuable to start thinking about:\n",
    "- What sort of things do we know?\n",
    "- What sort of expectations do we have?\n",
    "- What sort of qualitative things can we get from an exploratory analysis of the data?\n",
    "\n",
    "So, using k-Means clustering and PCA are a good start to do some sort of dimentionality reduction, some ways of geting the data to the point where you can look and ger some qualitative insights.\n",
    "Understand the general structure of it, you can start to see patterns, emerging data that make sense, or either confirm or possibly go against other theories or in grained beliefs that people have.\n",
    "-> Getting data down to that point is very importatnt.\n",
    "\n",
    "Quantittative viewpoint:\n",
    "Trying to understand causal connections like which features are actually causing it. It's important to use a lot of caution around that and never just sort of dump a bunch of data into a model with **lots of features** and then jsut naively look at the thing that have the strongest weights in your model and here's ***what*** driving it.\n",
    "\n",
    "#### Tips for aspiring Data Scientists\n",
    "There're 3 areas or part of this kind of work and you should think about which parts do you really enjoy the most.\n",
    "\n",
    "- For some people, it's the process of building things, of writing code, ...\n",
    "- If you really enjoy the analysis part, the statistical and mathematical side of things, there's a lot more you can there in terms of coming up to speed with new machine learning techniques, learning statistics more in depth.\n",
    "- On the communications and strategies side there's obviously a lot that you can do to improve your communication skills, undestand how to abstract from the details, how to abstract our the high level issues that are important to a company.\n",
    "\n",
    "\n",
    "Note: A quick overview on dimensionality reduction and PCA (principal component analysis):\n",
    "http://georgemdallas.wordpress.com/2013/10/30/principal-component-analysis-4-dummies-eigenvectors-eigenvalues-and-dimension-reduction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"798\" height=\"449\" src=\"https://www.youtube.com/embed/zS9SmHPVjJs\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"798\" height=\"449\" src=\"https://www.youtube.com/embed/zS9SmHPVjJs\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"798\" height=\"449\" src=\"https://www.youtube.com/embed/wuUQl3o_hVI\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"798\" height=\"449\" src=\"https://www.youtube.com/embed/wuUQl3o_hVI\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Assignment 3\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"798\" height=\"449\" src=\"https://www.youtube.com/embed/OWGuZuBxS8E\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Lesson 3 Recap\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"798\" height=\"449\" src=\"https://www.youtube.com/embed/u1Sh-BjiFfM\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
